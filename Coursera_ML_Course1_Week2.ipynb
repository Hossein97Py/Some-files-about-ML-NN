{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85aece8d",
   "metadata": {},
   "source": [
    "# Coursera Lab about Multiple Variable Linear Regression\n",
    "### Andrew Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7213fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get started\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edf939",
   "metadata": {},
   "source": [
    "Here is the dataset to work with:\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d415f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460,232,178])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522baf7",
   "metadata": {},
   "source": [
    "Initilize w, b as the numbers below which are close to the optimum values. This is only for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c588013",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b996abd",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad2a6a",
   "metadata": {},
   "source": [
    "# A: Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a983a26",
   "metadata": {},
   "source": [
    "### A_1: Model Prediction: element by element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4619db6",
   "metadata": {},
   "source": [
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cc9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x, w, b):\n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "        x: example with multiple features\n",
    "        w, b: model parameters\n",
    "    Return:\n",
    "        p: model prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = w[i] * x[i]\n",
    "        p = p + p_i\n",
    "    p = p + b\n",
    "    return p     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d196c55",
   "metadata": {},
   "source": [
    "let's test this function using initialized model parameters (w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efed3446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec value: [2104    5    1   45]\n",
      "prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = x_train[0, :]\n",
    "\n",
    "# make a prediction (now we are using the inital w, b)\n",
    "# as it was mentioned before, they are initialized near optimum values.\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "\n",
    "#print statements:\n",
    "print(f\"x_vec value: {x_vec}\")\n",
    "print(f\"prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769fc06",
   "metadata": {},
   "source": [
    "### A_2: Model Prediction: vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2959cc6",
   "metadata": {},
   "source": [
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    p = np.dot(x, w) + b\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a8b3e",
   "metadata": {},
   "source": [
    "let's test this function using initialized model parameters (w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73683406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec value: [2104    5    1   45]\n",
      "prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = x_train[0, :]\n",
    "\n",
    "# make a prediction (now we are using the inital w, b)\n",
    "# as it was mentioned before, they are initialized near optimum values.\n",
    "f_wb = predict(x_vec, w_init, b_init)\n",
    "\n",
    "#print statements:\n",
    "print(f\"x_vec value: {x_vec}\")\n",
    "print(f\"prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f28c5",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae059c",
   "metadata": {},
   "source": [
    "# B: computing model cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d20b1",
   "metadata": {},
   "source": [
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed78fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: Data, m example with n features\n",
    "        y: target value\n",
    "        w, b: model parameters\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range (m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        cost = cost + (f_wb_i - y[i])**2\n",
    "    cost = cost / (2 * m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36243a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : 1.5578904045996674e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(x_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317d2ab",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6993e0",
   "metadata": {},
   "source": [
    "# C: Gradient Descent With Multiple Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4c35d",
   "metadata": {},
   "source": [
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e354b51",
   "metadata": {},
   "source": [
    "### C_1: Compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "254fe6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: Data, m example with n features\n",
    "        y: target value\n",
    "        w, b: model parameters\n",
    "    Returns:\n",
    "        dj_dw which is an array with n (number of features) rows\n",
    "        dj_db which is a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = x.shape # number of training data and number of features\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range (m):               # iterate throug examples\n",
    "        temp_err = (np.dot(x[i], w) + b) - y[i]\n",
    "        \n",
    "        for j in range (n):           # iterate throug features\n",
    "            dj_dw[j] = dj_dw[j] + temp_err * x[i, j]            \n",
    "        dj_db = dj_db + temp_err      # is cumulated for all the examples (outer loop)\n",
    "        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    #print(m, n, dj_dw)    \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "#compute_gradient(x_train, y_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93635e",
   "metadata": {},
   "source": [
    "### C_2: Compute gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76cf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_init, b_init, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x                   : Data, m example with n features\n",
    "        y                   : target value\n",
    "        w_init, b_init      : initial model parameters (will be set to zero)\n",
    "        cost_function       : function to compute cost\n",
    "        gradient_function   : function to compute the gradient\n",
    "        alpha               : Learning rate\n",
    "        num_iters           : number of iterations to run gradient descent\n",
    "    Returns:\n",
    "        w                   : Updated values of parameters \n",
    "        b                   : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    for i in range (num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(x, y, w_init, b_init)\n",
    "        print(f\"iteration: {i}\\n cost: \")\n",
    "        \n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w_init - alpha * dj_dw               \n",
    "        b = b_init - alpha * dj_db              \n",
    "        \n",
    "        return (w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115250d2",
   "metadata": {},
   "source": [
    "Let's run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562fbb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [2.41e-01 5.59e-04 1.84e-04 6.03e-03]\n",
      "b:0.000145\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros((4,))\n",
    "initial_b = 0\n",
    "\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w, b = gradient_descent(x_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations)\n",
    "print(f\"w: {w}\\nb:{b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce767237",
   "metadata": {},
   "source": [
    "# This still needs work\n",
    "# 1401-04-24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f590fc176b1eb03cf0810251abf63876d6ecd1e4672f7f79bd667faca7e28e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
